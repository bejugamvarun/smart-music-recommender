{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GhoW5ref5iK",
        "colab_type": "text"
      },
      "source": [
        "# Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TPwjJ_2P89U",
        "colab_type": "code",
        "outputId": "5417edc3-d33b-4827-8f51-736c5f986dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "!pip install librosa==0.6.3 numpy soundfile==0.9.0 sklearn \n",
        "!pip install -q keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa==0.6.3 in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.5)\n",
            "Collecting soundfile==0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/42/b8a6afe407eab72ea1f526fcfffd4f5f330203483956662fa9638fd45669/SoundFile-0.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.47.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.14.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.22.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (1.4.1)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (4.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (2.1.8)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from soundfile==0.9.0) (1.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa==0.6.3) (42.0.2)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa==0.6.3) (0.31.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->soundfile==0.9.0) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8SP4KcrgIf6",
        "colab_type": "text"
      },
      "source": [
        "# Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJaYaXYvVNK",
        "colab_type": "code",
        "outputId": "c3ff3108-de4d-4c46-8b83-2f226b383ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import soundfile # to read audio file\n",
        "import numpy as np\n",
        "import librosa # to extract speech features\n",
        "import glob\n",
        "import os\n",
        "import pickle # to save model after training\n",
        "from sklearn.model_selection import train_test_split # for splitting training and testing\n",
        "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model\n",
        "from sklearn.metrics import accuracy_score # to measure how good we are\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, LSTM\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me-05JUqgRXh",
        "colab_type": "text"
      },
      "source": [
        "# Mount drive to fetch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNMzmDZ9wp35",
        "colab_type": "code",
        "outputId": "3b6c7e15-abcc-488a-cbab-e3d8abb57f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3JvJBYBgqqX",
        "colab_type": "text"
      },
      "source": [
        "# Function to extract features from the audio dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDr1jNALwqqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        if X.ndim >= 2:\n",
        "            X = np.mean(X, 1)\n",
        "        sample_rate = sound_file.samplerate\n",
        "        result = np.array([])\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYv3A5Y3g-xG",
        "colab_type": "text"
      },
      "source": [
        "Filter the required emotions - We use only 5 emotions for training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbV9sY2Hz4UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int2emotion = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "# we allow only these emotions ( feel free to tune this on your need )\n",
        "AVAILABLE_EMOTIONS = {\n",
        "    \"neutral\",\n",
        "    \"calm\",\n",
        "    \"happy\",\n",
        "    \"sad\",\n",
        "    \"angry\",\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYTNV2T9hLCV",
        "colab_type": "text"
      },
      "source": [
        "# Function to load data and split the training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDr3GuAz0c8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(test_size=0.2):\n",
        "    X, y = [], []\n",
        "    for file in glob.glob(\"/content/drive/My Drive/Dataset/*.wav\"):\n",
        "        # get the base name of the audio file\n",
        "        basename = os.path.basename(file)\n",
        "        # get the emotion label\n",
        "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
        "        # we allow only AVAILABLE_EMOTIONS we set\n",
        "        if emotion not in AVAILABLE_EMOTIONS:\n",
        "            continue\n",
        "        # extract speech features\n",
        "        features = extract_feature(file, mfcc=True, chroma=False, mel=False)\n",
        "        # add to data\n",
        "        X.append(features)\n",
        "        y.append(emotion)\n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nkB6U6b3JKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train1, y_test1 = load_data(test_size=0.30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lS8RNM-iBc1",
        "colab_type": "text"
      },
      "source": [
        "# Tailor the input dimension to fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGY7xryJ2gvG",
        "colab_type": "code",
        "outputId": "6767306f-c9f2-4f15-cd08-62d71e95d04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# print some details\n",
        "# number of samples in training data\n",
        "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
        "# number of samples in testing data\n",
        "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
        "# number of features used\n",
        "# this is a vector of features extracted \n",
        "# using extract_features() function\n",
        "print(\"[+] Number of features:\", X_train.shape[1])\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train=np.array(y_train1)\n",
        "y_test=np.array(y_test1)\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)\n",
        "\n",
        "print(x_traincnn.shape) \n",
        "print(x_testcnn.shape)\n",
        "print(y_train.shape) \n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Number of training samples: 604\n",
            "[+] Number of testing samples: 260\n",
            "[+] Number of features: 40\n",
            "(604, 40, 1)\n",
            "(260, 40, 1)\n",
            "(604, 5)\n",
            "(260, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQWbYRQUiIMP",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gChOx47xzTfV",
        "colab_type": "text"
      },
      "source": [
        "Model 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIq3z9AuM3o8",
        "colab_type": "code",
        "outputId": "10facef5-8e08-4832-cece-e2cf47674032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32,3,padding='same',activation='relu',input_shape=(40,1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(32,3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(64,3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(64,3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=5,activation = 'softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, np.array(y_train), batch_size=32, epochs=100, validation_data=(x_testcnn, np.array(y_test)))\n",
        "print(\"Accuracy: {:.2f}%\".format(cnnhistory.history['acc'][-1]*100))\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(cnnhistory.history['val_acc'][-1]*100))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 604 samples, validate on 260 samples\n",
            "Epoch 1/100\n",
            "604/604 [==============================] - 8s 13ms/step - loss: 4.7718 - acc: 0.2765 - val_loss: 1.8421 - val_acc: 0.2885\n",
            "Epoch 2/100\n",
            "604/604 [==============================] - 0s 344us/step - loss: 2.5216 - acc: 0.2616 - val_loss: 1.5266 - val_acc: 0.3423\n",
            "Epoch 3/100\n",
            "604/604 [==============================] - 0s 347us/step - loss: 2.1301 - acc: 0.2550 - val_loss: 1.6454 - val_acc: 0.2885\n",
            "Epoch 4/100\n",
            "604/604 [==============================] - 0s 346us/step - loss: 1.8018 - acc: 0.2831 - val_loss: 1.4807 - val_acc: 0.3385\n",
            "Epoch 5/100\n",
            "604/604 [==============================] - 0s 346us/step - loss: 1.7085 - acc: 0.2864 - val_loss: 1.4861 - val_acc: 0.3154\n",
            "Epoch 6/100\n",
            "604/604 [==============================] - 0s 361us/step - loss: 1.6031 - acc: 0.3212 - val_loss: 1.4821 - val_acc: 0.2808\n",
            "Epoch 7/100\n",
            "604/604 [==============================] - 0s 372us/step - loss: 1.5589 - acc: 0.3460 - val_loss: 1.4418 - val_acc: 0.3462\n",
            "Epoch 8/100\n",
            "604/604 [==============================] - 0s 364us/step - loss: 1.5326 - acc: 0.3394 - val_loss: 1.4268 - val_acc: 0.3192\n",
            "Epoch 9/100\n",
            "604/604 [==============================] - 0s 375us/step - loss: 1.4780 - acc: 0.3411 - val_loss: 1.4306 - val_acc: 0.3577\n",
            "Epoch 10/100\n",
            "604/604 [==============================] - 0s 405us/step - loss: 1.4544 - acc: 0.3560 - val_loss: 1.3784 - val_acc: 0.4000\n",
            "Epoch 11/100\n",
            "604/604 [==============================] - 0s 401us/step - loss: 1.5147 - acc: 0.3659 - val_loss: 1.4056 - val_acc: 0.3769\n",
            "Epoch 12/100\n",
            "604/604 [==============================] - 0s 373us/step - loss: 1.4364 - acc: 0.3758 - val_loss: 1.3737 - val_acc: 0.3769\n",
            "Epoch 13/100\n",
            "604/604 [==============================] - 0s 383us/step - loss: 1.4571 - acc: 0.3725 - val_loss: 1.3854 - val_acc: 0.4154\n",
            "Epoch 14/100\n",
            "604/604 [==============================] - 0s 390us/step - loss: 1.4102 - acc: 0.4056 - val_loss: 1.3468 - val_acc: 0.4115\n",
            "Epoch 15/100\n",
            "604/604 [==============================] - 0s 421us/step - loss: 1.3952 - acc: 0.3891 - val_loss: 1.3353 - val_acc: 0.4346\n",
            "Epoch 16/100\n",
            "604/604 [==============================] - 0s 383us/step - loss: 1.3843 - acc: 0.4007 - val_loss: 1.3203 - val_acc: 0.4423\n",
            "Epoch 17/100\n",
            "604/604 [==============================] - 0s 392us/step - loss: 1.3795 - acc: 0.3907 - val_loss: 1.3087 - val_acc: 0.4538\n",
            "Epoch 18/100\n",
            "604/604 [==============================] - 0s 397us/step - loss: 1.3425 - acc: 0.4272 - val_loss: 1.3283 - val_acc: 0.3846\n",
            "Epoch 19/100\n",
            "604/604 [==============================] - 0s 404us/step - loss: 1.3152 - acc: 0.4222 - val_loss: 1.2741 - val_acc: 0.4692\n",
            "Epoch 20/100\n",
            "604/604 [==============================] - 0s 376us/step - loss: 1.3008 - acc: 0.4470 - val_loss: 1.2689 - val_acc: 0.4423\n",
            "Epoch 21/100\n",
            "604/604 [==============================] - 0s 383us/step - loss: 1.3313 - acc: 0.3742 - val_loss: 1.3242 - val_acc: 0.4154\n",
            "Epoch 22/100\n",
            "604/604 [==============================] - 0s 387us/step - loss: 1.3300 - acc: 0.4073 - val_loss: 1.2563 - val_acc: 0.4577\n",
            "Epoch 23/100\n",
            "604/604 [==============================] - 0s 394us/step - loss: 1.2999 - acc: 0.4338 - val_loss: 1.2520 - val_acc: 0.4577\n",
            "Epoch 24/100\n",
            "604/604 [==============================] - 0s 450us/step - loss: 1.3154 - acc: 0.4338 - val_loss: 1.2296 - val_acc: 0.4962\n",
            "Epoch 25/100\n",
            "604/604 [==============================] - 0s 402us/step - loss: 1.2693 - acc: 0.4570 - val_loss: 1.2221 - val_acc: 0.4615\n",
            "Epoch 26/100\n",
            "604/604 [==============================] - 0s 395us/step - loss: 1.2322 - acc: 0.4785 - val_loss: 1.1891 - val_acc: 0.5154\n",
            "Epoch 27/100\n",
            "604/604 [==============================] - 0s 384us/step - loss: 1.2497 - acc: 0.4950 - val_loss: 1.1915 - val_acc: 0.5077\n",
            "Epoch 28/100\n",
            "604/604 [==============================] - 0s 389us/step - loss: 1.2139 - acc: 0.5083 - val_loss: 1.1836 - val_acc: 0.5192\n",
            "Epoch 29/100\n",
            "604/604 [==============================] - 0s 357us/step - loss: 1.2210 - acc: 0.4768 - val_loss: 1.1861 - val_acc: 0.5115\n",
            "Epoch 30/100\n",
            "604/604 [==============================] - 0s 371us/step - loss: 1.1810 - acc: 0.5381 - val_loss: 1.1622 - val_acc: 0.4923\n",
            "Epoch 31/100\n",
            "604/604 [==============================] - 0s 391us/step - loss: 1.1649 - acc: 0.5265 - val_loss: 1.1536 - val_acc: 0.4962\n",
            "Epoch 32/100\n",
            "604/604 [==============================] - 0s 396us/step - loss: 1.1900 - acc: 0.5116 - val_loss: 1.1396 - val_acc: 0.5192\n",
            "Epoch 33/100\n",
            "604/604 [==============================] - 0s 365us/step - loss: 1.2007 - acc: 0.5000 - val_loss: 1.1434 - val_acc: 0.5115\n",
            "Epoch 34/100\n",
            "604/604 [==============================] - 0s 375us/step - loss: 1.1538 - acc: 0.5397 - val_loss: 1.1116 - val_acc: 0.5423\n",
            "Epoch 35/100\n",
            "604/604 [==============================] - 0s 341us/step - loss: 1.1338 - acc: 0.5232 - val_loss: 1.0964 - val_acc: 0.5423\n",
            "Epoch 36/100\n",
            "604/604 [==============================] - 0s 360us/step - loss: 1.1108 - acc: 0.5265 - val_loss: 1.1036 - val_acc: 0.5000\n",
            "Epoch 37/100\n",
            "604/604 [==============================] - 0s 331us/step - loss: 1.1365 - acc: 0.5265 - val_loss: 1.0977 - val_acc: 0.5115\n",
            "Epoch 38/100\n",
            "604/604 [==============================] - 0s 331us/step - loss: 1.0870 - acc: 0.5497 - val_loss: 1.0902 - val_acc: 0.5500\n",
            "Epoch 39/100\n",
            "604/604 [==============================] - 0s 345us/step - loss: 1.1000 - acc: 0.5331 - val_loss: 1.0662 - val_acc: 0.5731\n",
            "Epoch 40/100\n",
            "604/604 [==============================] - 0s 362us/step - loss: 1.0516 - acc: 0.5877 - val_loss: 1.0787 - val_acc: 0.5692\n",
            "Epoch 41/100\n",
            "604/604 [==============================] - 0s 349us/step - loss: 1.0716 - acc: 0.5596 - val_loss: 1.0860 - val_acc: 0.5269\n",
            "Epoch 42/100\n",
            "604/604 [==============================] - 0s 341us/step - loss: 1.0446 - acc: 0.5828 - val_loss: 1.0505 - val_acc: 0.5846\n",
            "Epoch 43/100\n",
            "604/604 [==============================] - 0s 338us/step - loss: 1.0490 - acc: 0.5530 - val_loss: 1.0381 - val_acc: 0.5692\n",
            "Epoch 44/100\n",
            "604/604 [==============================] - 0s 364us/step - loss: 1.0074 - acc: 0.5811 - val_loss: 1.0337 - val_acc: 0.5769\n",
            "Epoch 45/100\n",
            "604/604 [==============================] - 0s 364us/step - loss: 0.9736 - acc: 0.6010 - val_loss: 1.0069 - val_acc: 0.5923\n",
            "Epoch 46/100\n",
            "604/604 [==============================] - 0s 361us/step - loss: 0.9818 - acc: 0.6341 - val_loss: 0.9968 - val_acc: 0.5808\n",
            "Epoch 47/100\n",
            "604/604 [==============================] - 0s 357us/step - loss: 0.9838 - acc: 0.5828 - val_loss: 1.0173 - val_acc: 0.5346\n",
            "Epoch 48/100\n",
            "604/604 [==============================] - 0s 343us/step - loss: 0.9744 - acc: 0.6291 - val_loss: 0.9704 - val_acc: 0.6077\n",
            "Epoch 49/100\n",
            "604/604 [==============================] - 0s 368us/step - loss: 0.9905 - acc: 0.6109 - val_loss: 1.0237 - val_acc: 0.6000\n",
            "Epoch 50/100\n",
            "604/604 [==============================] - 0s 375us/step - loss: 0.9994 - acc: 0.5728 - val_loss: 0.9989 - val_acc: 0.5885\n",
            "Epoch 51/100\n",
            "604/604 [==============================] - 0s 364us/step - loss: 0.9024 - acc: 0.6407 - val_loss: 0.9818 - val_acc: 0.6192\n",
            "Epoch 52/100\n",
            "604/604 [==============================] - 0s 351us/step - loss: 0.9404 - acc: 0.6275 - val_loss: 0.9838 - val_acc: 0.5846\n",
            "Epoch 53/100\n",
            "604/604 [==============================] - 0s 360us/step - loss: 0.9116 - acc: 0.6391 - val_loss: 0.9798 - val_acc: 0.6000\n",
            "Epoch 54/100\n",
            "604/604 [==============================] - 0s 349us/step - loss: 0.8569 - acc: 0.6887 - val_loss: 0.9736 - val_acc: 0.6154\n",
            "Epoch 55/100\n",
            "604/604 [==============================] - 0s 381us/step - loss: 0.9073 - acc: 0.6341 - val_loss: 0.9640 - val_acc: 0.6000\n",
            "Epoch 56/100\n",
            "604/604 [==============================] - 0s 366us/step - loss: 0.8835 - acc: 0.6540 - val_loss: 0.9714 - val_acc: 0.5846\n",
            "Epoch 57/100\n",
            "604/604 [==============================] - 0s 366us/step - loss: 0.8586 - acc: 0.6623 - val_loss: 0.9442 - val_acc: 0.6077\n",
            "Epoch 58/100\n",
            "604/604 [==============================] - 0s 385us/step - loss: 0.8764 - acc: 0.6623 - val_loss: 0.9577 - val_acc: 0.6308\n",
            "Epoch 59/100\n",
            "604/604 [==============================] - 0s 371us/step - loss: 0.9276 - acc: 0.6507 - val_loss: 0.9970 - val_acc: 0.6154\n",
            "Epoch 60/100\n",
            "604/604 [==============================] - 0s 375us/step - loss: 0.8906 - acc: 0.6589 - val_loss: 0.9822 - val_acc: 0.6000\n",
            "Epoch 61/100\n",
            "604/604 [==============================] - 0s 335us/step - loss: 0.8656 - acc: 0.6440 - val_loss: 1.0053 - val_acc: 0.5654\n",
            "Epoch 62/100\n",
            "604/604 [==============================] - 0s 354us/step - loss: 0.8726 - acc: 0.6424 - val_loss: 0.9653 - val_acc: 0.6231\n",
            "Epoch 63/100\n",
            "604/604 [==============================] - 0s 368us/step - loss: 0.8148 - acc: 0.6755 - val_loss: 0.9376 - val_acc: 0.6538\n",
            "Epoch 64/100\n",
            "604/604 [==============================] - 0s 377us/step - loss: 0.8165 - acc: 0.6772 - val_loss: 0.9383 - val_acc: 0.6423\n",
            "Epoch 65/100\n",
            "604/604 [==============================] - 0s 371us/step - loss: 0.8060 - acc: 0.6937 - val_loss: 0.9276 - val_acc: 0.6538\n",
            "Epoch 66/100\n",
            "604/604 [==============================] - 0s 332us/step - loss: 0.8007 - acc: 0.6954 - val_loss: 0.9433 - val_acc: 0.6385\n",
            "Epoch 67/100\n",
            "604/604 [==============================] - 0s 376us/step - loss: 0.7458 - acc: 0.7169 - val_loss: 0.9281 - val_acc: 0.6462\n",
            "Epoch 68/100\n",
            "604/604 [==============================] - 0s 396us/step - loss: 0.7769 - acc: 0.6987 - val_loss: 0.9234 - val_acc: 0.6692\n",
            "Epoch 69/100\n",
            "604/604 [==============================] - 0s 355us/step - loss: 0.8194 - acc: 0.6623 - val_loss: 0.9175 - val_acc: 0.6654\n",
            "Epoch 70/100\n",
            "604/604 [==============================] - 0s 354us/step - loss: 0.7520 - acc: 0.7103 - val_loss: 0.9115 - val_acc: 0.6692\n",
            "Epoch 71/100\n",
            "604/604 [==============================] - 0s 372us/step - loss: 0.7795 - acc: 0.6871 - val_loss: 0.9008 - val_acc: 0.6500\n",
            "Epoch 72/100\n",
            "604/604 [==============================] - 0s 362us/step - loss: 0.6983 - acc: 0.7268 - val_loss: 0.8958 - val_acc: 0.6577\n",
            "Epoch 73/100\n",
            "604/604 [==============================] - 0s 352us/step - loss: 0.7372 - acc: 0.7235 - val_loss: 0.8547 - val_acc: 0.7000\n",
            "Epoch 74/100\n",
            "604/604 [==============================] - 0s 378us/step - loss: 0.6854 - acc: 0.7334 - val_loss: 0.9060 - val_acc: 0.6654\n",
            "Epoch 75/100\n",
            "604/604 [==============================] - 0s 346us/step - loss: 0.7300 - acc: 0.7136 - val_loss: 0.9002 - val_acc: 0.6500\n",
            "Epoch 76/100\n",
            "604/604 [==============================] - 0s 346us/step - loss: 0.6904 - acc: 0.7318 - val_loss: 0.8617 - val_acc: 0.6808\n",
            "Epoch 77/100\n",
            "604/604 [==============================] - 0s 362us/step - loss: 0.6921 - acc: 0.7202 - val_loss: 0.8508 - val_acc: 0.6769\n",
            "Epoch 78/100\n",
            "604/604 [==============================] - 0s 359us/step - loss: 0.7046 - acc: 0.7219 - val_loss: 0.8519 - val_acc: 0.6846\n",
            "Epoch 79/100\n",
            "604/604 [==============================] - 0s 357us/step - loss: 0.6647 - acc: 0.7235 - val_loss: 0.9058 - val_acc: 0.6538\n",
            "Epoch 80/100\n",
            "604/604 [==============================] - 0s 366us/step - loss: 0.6413 - acc: 0.7467 - val_loss: 0.8270 - val_acc: 0.6885\n",
            "Epoch 81/100\n",
            "604/604 [==============================] - 0s 360us/step - loss: 0.6519 - acc: 0.7401 - val_loss: 0.8362 - val_acc: 0.6769\n",
            "Epoch 82/100\n",
            "604/604 [==============================] - 0s 367us/step - loss: 0.5818 - acc: 0.7732 - val_loss: 0.8388 - val_acc: 0.6808\n",
            "Epoch 83/100\n",
            "604/604 [==============================] - 0s 365us/step - loss: 0.6614 - acc: 0.7517 - val_loss: 0.8682 - val_acc: 0.6692\n",
            "Epoch 84/100\n",
            "604/604 [==============================] - 0s 368us/step - loss: 0.5851 - acc: 0.7831 - val_loss: 0.8276 - val_acc: 0.6615\n",
            "Epoch 85/100\n",
            "604/604 [==============================] - 0s 362us/step - loss: 0.6705 - acc: 0.7301 - val_loss: 0.8578 - val_acc: 0.6500\n",
            "Epoch 86/100\n",
            "604/604 [==============================] - 0s 362us/step - loss: 0.6919 - acc: 0.7467 - val_loss: 0.8374 - val_acc: 0.6962\n",
            "Epoch 87/100\n",
            "604/604 [==============================] - 0s 372us/step - loss: 0.5690 - acc: 0.7864 - val_loss: 0.8237 - val_acc: 0.6962\n",
            "Epoch 88/100\n",
            "604/604 [==============================] - 0s 352us/step - loss: 0.6104 - acc: 0.7616 - val_loss: 0.8147 - val_acc: 0.6923\n",
            "Epoch 89/100\n",
            "604/604 [==============================] - 0s 359us/step - loss: 0.5706 - acc: 0.7699 - val_loss: 0.8192 - val_acc: 0.7154\n",
            "Epoch 90/100\n",
            "604/604 [==============================] - 0s 340us/step - loss: 0.5909 - acc: 0.7848 - val_loss: 0.8149 - val_acc: 0.6885\n",
            "Epoch 91/100\n",
            "604/604 [==============================] - 0s 348us/step - loss: 0.5512 - acc: 0.7881 - val_loss: 0.7915 - val_acc: 0.6962\n",
            "Epoch 92/100\n",
            "604/604 [==============================] - 0s 353us/step - loss: 0.5559 - acc: 0.7997 - val_loss: 0.8007 - val_acc: 0.7077\n",
            "Epoch 93/100\n",
            "604/604 [==============================] - 0s 367us/step - loss: 0.5739 - acc: 0.7715 - val_loss: 0.8366 - val_acc: 0.6538\n",
            "Epoch 94/100\n",
            "604/604 [==============================] - 0s 386us/step - loss: 0.5296 - acc: 0.8129 - val_loss: 0.8695 - val_acc: 0.6731\n",
            "Epoch 95/100\n",
            "604/604 [==============================] - 0s 354us/step - loss: 0.5418 - acc: 0.8046 - val_loss: 0.8116 - val_acc: 0.6731\n",
            "Epoch 96/100\n",
            "604/604 [==============================] - 0s 356us/step - loss: 0.4960 - acc: 0.8377 - val_loss: 0.7638 - val_acc: 0.7154\n",
            "Epoch 97/100\n",
            "604/604 [==============================] - 0s 362us/step - loss: 0.4915 - acc: 0.8096 - val_loss: 0.8222 - val_acc: 0.7077\n",
            "Epoch 98/100\n",
            "604/604 [==============================] - 0s 358us/step - loss: 0.5070 - acc: 0.8013 - val_loss: 0.8685 - val_acc: 0.7000\n",
            "Epoch 99/100\n",
            "604/604 [==============================] - 0s 369us/step - loss: 0.5327 - acc: 0.7980 - val_loss: 0.8391 - val_acc: 0.6962\n",
            "Epoch 100/100\n",
            "604/604 [==============================] - 0s 350us/step - loss: 0.5198 - acc: 0.7881 - val_loss: 0.8161 - val_acc: 0.7000\n",
            "Accuracy: 78.81%\n",
            "Validation Accuracy: 70.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMkCkYkJzcf2",
        "colab_type": "text"
      },
      "source": [
        "Train new one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpurTqKU_iL",
        "colab_type": "text"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57t-XY1z5y2Z",
        "colab_type": "code",
        "outputId": "bddb8869-690a-4c26-b971-6d2d4873536b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_name = 'Emotion_Voice_Detection_Model1.h5'\n",
        "model_path = os.path.join('/content', model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/Emotion_Voice_Detection_Model1.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5VNm6V9icHX",
        "colab_type": "text"
      },
      "source": [
        "Save the model to a json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVXSLCQ6qjfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model1.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJcoZDT4Ws-Y",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx3A92RCW2L5",
        "colab_type": "text"
      },
      "source": [
        "Process the model for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgogkonq1bRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "feature_test=extract_feature('filename_sad.wav', mfcc=True, chroma=False, mel=False)\n",
        "livedf2 = feature_test\n",
        "livedf2= pd.DataFrame(data=livedf2)\n",
        "livedf2 = livedf2.stack().to_frame().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MD1Z4JgmogL",
        "colab_type": "code",
        "outputId": "32f740d0-deb6-4351-e6dd-6b3a45f60eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "livedf2"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-204.521686</td>\n",
              "      <td>67.135924</td>\n",
              "      <td>5.374407</td>\n",
              "      <td>15.67512</td>\n",
              "      <td>-6.406191</td>\n",
              "      <td>7.32221</td>\n",
              "      <td>-3.289051</td>\n",
              "      <td>3.839779</td>\n",
              "      <td>-1.570694</td>\n",
              "      <td>6.404727</td>\n",
              "      <td>1.85788</td>\n",
              "      <td>2.131837</td>\n",
              "      <td>0.491811</td>\n",
              "      <td>1.17804</td>\n",
              "      <td>-0.260022</td>\n",
              "      <td>3.017572</td>\n",
              "      <td>3.76518</td>\n",
              "      <td>2.88533</td>\n",
              "      <td>5.730032</td>\n",
              "      <td>7.221426</td>\n",
              "      <td>6.92007</td>\n",
              "      <td>9.646391</td>\n",
              "      <td>7.658868</td>\n",
              "      <td>7.259945</td>\n",
              "      <td>6.227987</td>\n",
              "      <td>5.43227</td>\n",
              "      <td>4.716178</td>\n",
              "      <td>2.922552</td>\n",
              "      <td>3.03751</td>\n",
              "      <td>2.165741</td>\n",
              "      <td>0.664761</td>\n",
              "      <td>1.398457</td>\n",
              "      <td>2.055024</td>\n",
              "      <td>2.014336</td>\n",
              "      <td>0.822774</td>\n",
              "      <td>2.907574</td>\n",
              "      <td>3.921482</td>\n",
              "      <td>2.361266</td>\n",
              "      <td>2.968615</td>\n",
              "      <td>3.139112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          1         2   ...        37        38        39\n",
              "            0          0         0  ...         0         0         0\n",
              "0 -204.521686  67.135924  5.374407  ...  2.361266  2.968615  3.139112\n",
              "\n",
              "[1 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-DW0hB1n0Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test= np.expand_dims(livedf2, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSyTfNflqD7T",
        "colab_type": "code",
        "outputId": "95fe9161-f22b-4b18-e840-fcb9cbe5926b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_test.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 40, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsohvmTWqRYS",
        "colab_type": "text"
      },
      "source": [
        "Load model and run prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp49NDzM7Rt3",
        "colab_type": "code",
        "outputId": "ee6ac74a-a05e-4222-da9e-5d7067793ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "json_file = open('model1.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/Emotion_Voice_Detection_Model1.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "#score = loaded_model.evaluate(, y_test, verbose=0)\n",
        "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
        "\n",
        "\n",
        "preds = loaded_model.predict(input_test, \n",
        "                         batch_size=32, \n",
        "                         verbose=1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "1/1 [==============================] - 6s 6s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsZkKmvVK65",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmvOpi268bEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds1=preds.argmax(axis=1)\n",
        "\n",
        "abc = preds1.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((abc)))\n",
        "\n",
        "preddf = pd.DataFrame({'predictedvalues': predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUeW51K7rvFh",
        "colab_type": "code",
        "outputId": "323a8a5a-5701-43ae-e6fc-acfd3892c151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "preddf\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictedvalues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  predictedvalues\n",
              "0             sad"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ln1HRTBt7ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}